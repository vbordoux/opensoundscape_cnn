{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.annotations import BoxedAnnotations\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and validation set and train a Resnet-18 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_experiment = 'texel_baseline_20250331'\n",
    "train_set_dir = os.path.join('/home/reindert/Valentin_REVO/surfperch_toshare/eval_texel Outputs/september 2024/surfperch/labeled_outputs/', name_experiment)\n",
    "\n",
    "pos_samples_file = os.listdir(os.path.join(train_set_dir, 'downsweep')) \n",
    "neg_samples_file = os.listdir(os.path.join(train_set_dir, 'Unknown'))\n",
    "\n",
    "pos_samples_file = [os.path.join(train_set_dir, 'downsweep', file) for file in pos_samples_file]\n",
    "neg_samples_file = [os.path.join(train_set_dir, 'Unknown', file) for file in neg_samples_file]\n",
    "\n",
    "df_pos = pd.DataFrame()\n",
    "df_neg = pd.DataFrame()\n",
    "\n",
    "# Add positive sample file in the dataframe in a column file and create a column label with 1\n",
    "df_pos['file'] = pos_samples_file\n",
    "df_pos['start_time'] = 0.0\n",
    "df_pos['end_time'] = 5.0\n",
    "df_pos['downsweep'] = 1\n",
    "\n",
    "# Add negative sample file in the dataframe in a column file and create a column label with 0\n",
    "df_neg['file'] = neg_samples_file\n",
    "df_neg['start_time'] = 0.0\n",
    "df_neg['end_time'] = 5.0\n",
    "df_neg['downsweep'] = 0\n",
    "\n",
    "# concatenate the two dataframe\n",
    "df_trainset = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "df_trainset['downsweep'].value_counts()\n",
    "\n",
    "# Save the df as csv in the current repo\n",
    "df_trainset.to_csv('train_set_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Change to 5-fold validation\n",
    "# Prepare train and valid set\n",
    "import sklearn.model_selection\n",
    "\n",
    "df_trainset = pd.read_csv('train_set_baseline.csv', index_col=[0,1,2])\n",
    "\n",
    "# Add a class column called background which is not(downsweep)\n",
    "# df_trainset['background'] = 1 - df_trainset['downsweep']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = sklearn.model_selection.train_test_split(df_trainset, test_size=0.2, random_state=0, stratify=df_trainset['downsweep'])\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create the 5-fold validation object\n",
    "seed = 0\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "fish_sound ='downsweep'\n",
    "\n",
    "# Iterate over the folds\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df, train_df[fish_sound])):\n",
    "    # For verification and debugging purposes\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"Train index: {train_index}\")\n",
    "    print(f\"Test index: {test_index}\")\n",
    "    print(\"size of each label in train set\")\n",
    "    print(train_df.iloc[test_index][fish_sound].value_counts())\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape import CNN\n",
    "# We use Resnet as most common architeture used in Bioacoustics (ref: Stowell 2022)\n",
    "# Resnet 18 because how dataset is small (avoid overfitting)\n",
    "\n",
    "architecture = 'resnet18' \n",
    "class_list = ['downsweep']\n",
    "model = CNN(architecture=architecture,\n",
    "            classes=class_list,\n",
    "            sample_duration=5.0,\n",
    "            overlay_df=None)\n",
    "\n",
    "print(f\"model.device is {model.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subprocess / preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from opensoundscape.preprocess.actions import Action\n",
    "# from opensoundscape.preprocess.action_functions import pcen\n",
    "\n",
    "# # TODO - Not working, returns blank spectrums, assuming pcen is called from librosa with require data to correct scale\n",
    "\n",
    "# model.preprocessor.insert_action(\n",
    "#     action_index=\"PCEN\",  # give it a name\n",
    "#     action=Action(pcen),  # the action object\n",
    "#     after_key=\"bandpass\",  # where to put it (can also use before_key=...)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check spectrograms visuals\n",
    "Show samples of the training set, so data augmentation are visible as well, but deactivated for validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.data_selection import resample\n",
    "augmented_train_df = resample(train_df, n_samples_per_class=200, n_samples_without_labels=200, random_state=0)\n",
    "train_df.shape\n",
    "augmented_train_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa import pcen\n",
    "model.preprocessor.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.preprocess.utils import show_tensor_grid\n",
    "from opensoundscape import AudioFileDataset\n",
    "from  opensoundscape.preprocess.preprocessors import PCENPreprocessor\n",
    "from opensoundscape import CNN, SpectrogramPreprocessor\n",
    "from opensoundscape.preprocess.actions import Action\n",
    "from opensoundscape.preprocess.action_functions import pcen\n",
    "\n",
    "sample_rate = 32000\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = SpectrogramPreprocessor(5.0, overlay_df=train_df)\n",
    "preprocessor.pipeline.load_audio.set(sample_rate=sample_rate)\n",
    "preprocessor.pipeline.bandpass.set(min_f=50, max_f=2000)\n",
    "preprocessor.pipeline.to_spec.set(window_samples = 4 * (sample_rate // 100),\n",
    "                                        # overlap_samples = None,\n",
    "                                        # fft_size = None,\n",
    "                                        dB_scale = True,\n",
    "                                        # scaling = 'spectrum'\n",
    "                                        )\n",
    "\n",
    "# Augmentation\n",
    "preprocessor.pipeline.random_trim_audio.bypass = True\n",
    "preprocessor.pipeline.time_mask.bypass = True\n",
    "preprocessor.pipeline.time_mask.set(max_masks=2, max_width=0.1)\n",
    "preprocessor.pipeline.frequency_mask.bypass = True\n",
    "preprocessor.pipeline.frequency_mask.set(max_masks=2, max_width=0.1)\n",
    "preprocessor.pipeline.add_noise.bypass = True\n",
    "preprocessor.pipeline.random_affine.bypass = True\n",
    "\n",
    "# model.preprocessor.pipeline.overlay.bypass = True\n",
    "# preprocessor.pipeline.overlay.set(overlay_class='different', overlay_weight=0.5)\n",
    "# preprocessor.insert_action(\n",
    "#     action_index=\"PCEN\",  # give it a name\n",
    "#     action=Action(pcen),  # the action object\n",
    "#     after_key=\"bandpass\",  # where to put it (can also use before_key=...)\n",
    "# )\n",
    "# preprocessor.insert_action(\n",
    "#     action_index=\"to_log\",  # give it a name\n",
    "#     action=Action(amplitude_to_db),  # the action object\n",
    "#     after_key=\"PCEN\",  # where to put it (can also use before_key=...)\n",
    "# )\n",
    "\n",
    "\n",
    "model.preprocessor = preprocessor\n",
    "\n",
    "dataset = AudioFileDataset(train_df, model.preprocessor)\n",
    "dataset.preprocessor.pipeline.overlay.bypass = True\n",
    "# dataset.preprocessor.pipeline.overlay.set(overlay_class=train_df.sample(50))\n",
    "\n",
    "sample_idx = 15\n",
    "tensors = [dataset[i].data for i in range(sample_idx, sample_idx + 9)]\n",
    "sample_labels = [list(dataset[i].labels[dataset[i].labels > 0].index) for i in range(sample_idx, sample_idx + 9)]\n",
    "\n",
    "_ = show_tensor_grid(tensors, 3, labels=sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "checkpoint_folder = Path(\"model_training_checkpoints\")\n",
    "checkpoint_folder.mkdir(exist_ok=True)\n",
    "\n",
    "model.train(\n",
    "    augmented_train_df,\n",
    "    valid_df,\n",
    "    epochs=5,\n",
    "    batch_size=8,\n",
    "    num_workers=16,\n",
    "    save_interval=5,  # save checkpoint every 10 epochs\n",
    "    save_path=checkpoint_folder,  # location to save checkpoints\n",
    "    progress_bar=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files_path = '/home/reindert/Valentin_REVO/surfperch_toshare/eval_texel Data/september 2024/test_set/'\n",
    "test_files_list = os.listdir(test_files_path)\n",
    "\n",
    "# Create a list of all wav files with files ending by .wav\n",
    "wav_files = sorted([file for file in test_files_list if file.endswith('.wav')])\n",
    "annot_files = sorted([file for file in test_files_list if file.endswith('.txt')])\n",
    "\n",
    "wav_files = [os.path.join(test_files_path, file) for file in wav_files]\n",
    "annot_files = [os.path.join(test_files_path, file) for file in annot_files]\n",
    "\n",
    "print(\"Checking files order\\n\", wav_files[:3])\n",
    "print(annot_files[:3])\n",
    "\n",
    "selection_files = annot_files\n",
    "audio_files = wav_files\n",
    "\n",
    "annotations = BoxedAnnotations.from_raven_files(raven_files=selection_files, audio_files=audio_files, annotation_column='Type')\n",
    "\n",
    "clip_duration = 5.0\n",
    "clip_overlap = 0\n",
    "min_label_overlap = 0.2\n",
    "species_of_interest = [fish_sound]\n",
    "\n",
    "clip_labels = annotations.clip_labels(\n",
    "    clip_duration=clip_duration,\n",
    "    clip_overlap=clip_overlap,\n",
    "    min_label_overlap=min_label_overlap,\n",
    "    class_subset=species_of_interest)\n",
    "\n",
    "clip_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Test set from pickle file\n",
    "# Similar path to the one used in create_test_set_data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test set from a pickle file instead of creating a new one\n",
    "\n",
    "# Format test_set_df to match the format of the clip_labels\n",
    "test_set_path = '/home/reindert/Valentin_REVO/surfperch_toshare/eval_texel Outputs/september 2024/surfperch/test_set/'\n",
    "test_files_path = '/home/reindert/Valentin_REVO/surfperch_toshare/eval_texel Data/september 2024/test_set/'\n",
    "fish_sound = 'A'\n",
    "\n",
    "# load df from pickle\n",
    "with open(os.path.join(test_set_path, 'test_set.pkl'), 'rb') as f:\n",
    "    test_set_df = pd.read_pickle(f)\n",
    "\n",
    "# Modify the format of the pickle to be compatible with opensoundscape\n",
    "test_set_df = test_set_df.drop(columns=['Label', 'Embedding'])\n",
    "test_set_df = test_set_df.rename(columns={'label_int': fish_sound, 'Starttime': 'start_time', 'Endtime': 'end_time', 'filename': 'file'})\n",
    "test_set_df[fish_sound] = test_set_df[fish_sound].astype(bool)\n",
    "test_set_df['file'] = test_files_path + test_set_df['file']\n",
    "test_set_df = test_set_df.set_index(['file', 'start_time', 'end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_testset = model.predict(clip_labels, batch_size=64, num_workers=16, activation_layer='sigmoid', wandb_session=wandb_session)\n",
    "predict_validset = model.predict(valid_df, batch_size=8, num_workers=16, activation_layer='sigmoid', wandb_session=wandb_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# Compute precision from logits and labels\n",
    "valid_labels = valid_df['A'].values\n",
    "valid_pred = predict_validset['A'].values.round() #Threshold = 0.5\n",
    "\n",
    "precision_valid = precision_score(valid_labels, valid_pred, pos_label=1, average='binary')\n",
    "recall_valid = recall_score(valid_labels, valid_pred, pos_label=1, average='binary')\n",
    "f1_valid = f1_score(valid_labels, valid_pred, pos_label=1, average='binary')\n",
    "auc_roc_valid = roc_auc_score(valid_labels, predict_validset['A'].values)\n",
    "precision, recall, _thresholds = precision_recall_curve(valid_labels, predict_validset['A'].values)\n",
    "auc_precision_recall_valid = auc(recall, precision)\n",
    "\n",
    "test_labels = clip_labels['A'].values\n",
    "test_pred = pred_testset['A'].values.round()\n",
    "\n",
    "precision_test = precision_score(test_labels, test_pred, pos_label=1, average='binary')\n",
    "recall_test = recall_score(test_labels, test_pred, pos_label=1, average='binary')\n",
    "f1_test = f1_score(test_labels, test_pred, pos_label=1, average='binary')\n",
    "auc_roc_test = roc_auc_score(test_labels, pred_testset['A'].values)\n",
    "precision, recall, _thresholds = precision_recall_curve(test_labels, pred_testset['A'].values)\n",
    "auc_precision_recall_test = auc(recall, precision)\n",
    "\n",
    "# print all metrics\n",
    "print(\"Validation Set\")\n",
    "print(\"Precision valid: \", precision_valid)\n",
    "print(\"Recall valid: \", recall_valid)\n",
    "print(\"F1 valid: \", f1_valid)\n",
    "print(\"AUC ROC valid: \", auc_roc_valid)\n",
    "print(\"AUC precision recall: \", auc_precision_recall_valid)\n",
    "\n",
    "print(\"\\n\\nTest Set\")\n",
    "print(\"Precision test: \", precision_test)\n",
    "print(\"Recall test: \", recall_test)\n",
    "print(\"F1 test: \", f1_test)\n",
    "print(\"AUC ROC test: \", auc_roc_test)\n",
    "print(\"AUC precision recall: \", auc_precision_recall_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.items()\n",
    "avg_valid = {}\n",
    "for key, value in zip(metrics.keys(), metrics.values()):\n",
    "    avg_valid[key] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pseudo dictionary of metrics for test\n",
    "\n",
    "metrics = {'Precision_valid': [0.5,0.2], 'Recall_valid': [0.5,0.2], 'F1_valid': [0.5,0.2]}\n",
    "\n",
    "avg_valid = {}\n",
    "for key, value in zip(metrics.keys(), metrics.values()):\n",
    "    # v is the list of grades for student k\n",
    "    avg_valid[key] = sum(value)/ float(len(value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surfperch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
